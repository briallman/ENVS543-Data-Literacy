---
title: "Textual Analysis"
date: 10/24/2024
author: "Briana Allman"
format: html
editor: visual
---

## Textual Analysis

***Regular Expressions: Plotting the number of classes in the 1XX, 2XX, and 3XX levels and making a word cloud with class name info.***

Loading in Packages (Hidden)

```{r setup, include=FALSE}

library(tidyverse)
library(stringr)
library(readr)
library(lubridate)
library(ggplot2)
library(wordcloud2)
library(dplyr)
library(tidytext)
library(htmlwidgets)
library(tidyr)
```

Reading in Data

```{r}
url <- "https://raw.githubusercontent.com/DyerlabTeaching/Textual-Data/refs/heads/main/data/ENVSclasses.txt?token=GHSAT0AAAAAACWO27UIA46V72P7DBZEP5EKZYZFFXQ"

envs <- read_lines( url )

head(envs, 25)
```

Data Exploration

```{r}
# Creating an index based on the detection of "ENVS"
str_detect(envs, "ENVS") -> idx

envs[idx]

# Cuts it down a good but...but there are still extra things in the string
length(envs)
length(envs[idx])

# Narrowing down our search: Pattern Matching -> Identify what we mean when we say we are looking for 4 uppercase letters followed by 3 numbers followed by additional text -> REGULAR EXPRESSIONS
```

Regular Expressions

```{r}
envs101 <- envs[1]
envs101

# Matching & Searching Within
str_view(envs101, "ENVS")

str_view(envs101, "Hour")

str_view_all(envs101, "o")

# Shorthands -> Allows us to match any numerical digit -> [:digit:]
str_view(envs101, "[:digit:]")

# Finds 3 digits right next to each other
str_view(envs101, "[:digit:]{2,3}")

# Punctuation
str_view(envs101, "[:punct:]")

# Letters
str_view(envs101, "[:alpha:]")

# Lowercase
str_view(envs101, "[:lower:]")

# Uppercase
str_view(envs101, "[:upper:]")

# Space
str_view(envs101, "[:space:]")

# ALL TOGEHTER

str_view(envs, "[:alpha:]{4} [:digit:]{3}")

str_view(envs, "[:upper:]{4} [:digit:]{3}")

# Be Careful -> wrong
str_view(envs, "[:lower:]{4} [:digit:]{3}")

str_view( envs101, "[A-Z]{4} [0-9]{3}")
```

```{r}
# Starting point class 2

pattern <- "^[A-Z]{4} [0-9]{3}.+[0-9] Hour[s]?\\.$"
grepl(pattern, envs) -> idx
titles <- envs[idx]
titles

str_split(titles, pattern = "\\.")
str_split(titles, pattern = "\\.", simplify = TRUE) -> raw   #This is a Matrix


head (raw)

data.frame(course = raw[,1],
                           title = str_trim(raw[,2]),
                           hours = str_trim(raw[,3])) %>% 
  mutate(hours = str_remove(hours, " Hours?$")) -> df

# Splitting the course to seperate program
df <- df %>%
  separate(course, into = c("program", "course"), sep = " ")

# Making them numeric and making topics 1 credit
df <- df %>%
  mutate(hours = case_when(
    str_detect(hours, "-") ~ as.numeric(str_extract(hours, "^[0-9]+")),
    TRUE ~ as.numeric(hours)
  ))
```

Creating Plot for Classes

```{r}
df <- df %>%
  mutate(course = as.numeric(course))

# Extract course level by taking the hundreds digit directly from numeric values
envs_levels <- as.character(floor(df$course / 100) * 100)

# Convert to a data frame for easier manipulation
envs_levels_df <- tibble(course = df$course, level = envs_levels)

# Group by general course level (100, 200, etc.) and count the courses in each
level_counts <- envs_levels_df %>%
  group_by(level) %>%
  summarise(count = n(), .groups = 'drop')

# Check if level_counts has data
print(level_counts)

# Plotting the course levels
ggplot(level_counts, aes(x = level, y = count, fill = level)) +
  geom_bar(stat = "identity", width = 0.6) +
  scale_fill_brewer(palette = "Blues") +
  theme_minimal() +
  labs(
    title = "Number of Courses by Level",
    x = "Course Level",
    y = "Number of Courses"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 16),
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    legend.position = "none"
  ) +
  geom_text(aes(label = count), vjust = -0.3, size = 4) +
  expand_limits(y = max(level_counts$count) * 1.1)
```

Word Cloud based on word frequency in course titles

```{r}
# Step 1: Tokenize the words in the course titles
word_freq_2 <- df %>%
  unnest_tokens(word, title) %>%  # Break titles into individual words
  count(word, sort = TRUE)        # Count each unique word's occurrence

# Step 2: Remove common stop words
library(tidytext)
word_freq_2 <- word_freq_2 %>%
  anti_join(stop_words, by = "word")

# Step 3: Generate the word cloud
wordcloud2(word_freq_2, size = 1.0)
```
